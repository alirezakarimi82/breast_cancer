{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training classifier based on PCA data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, using the PCA transformed arrays of train and test image sets, a variety of different classification algorithms have been employed to recognize the type of tumor (malignant or benign). In order to find the optimal hyperparameters for each classifier, a grid search is utilized which compares the outcomes using a 5-fold cross validation scheme. Eventually, for each model, the best hyperparameters along with different classification metrics (accuracy, recall, F$_1$ score, and the recognition rate) are calculated and stored in a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import recall_score, fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_data.csv')\n",
    "df_test  = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('pca_data.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train = data['arr_0']\n",
    "Z_test  = data['arr_1']\n",
    "\n",
    "y_train = data['arr_2']\n",
    "y_test  = data['arr_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'LogisticRegression' : LogisticRegression(),\n",
    "          'KNN': KNeighborsClassifier(),\n",
    "          'GaussianNB': GaussianNB(),\n",
    "          'RandomForest': RandomForestClassifier(random_state=42),\n",
    "          'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "          'GradientBoost': GradientBoostingClassifier(random_state=42),\n",
    "          'SVM': SVC(random_state=42)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_model = {'LogisticRegression': {'penalty': ['l1', 'l2'],\n",
    "                                       'C': np.logspace(-3, 3, 14)},\n",
    "                'KNN': {'n_neighbors': [5, 7, 15],\n",
    "                                         'weights': ['uniform', 'distance']},\n",
    "                'GaussianNB': {},\n",
    "                'RandomForest': {'n_estimators': [100, 150, 200],\n",
    "                                           'max_depth': [None, 5, 7, 11]},\n",
    "                'AdaBoost': {'n_estimators': [100, 150, 200]},\n",
    "                'GradientBoost': {'n_estimators': [100, 150, 200]},\n",
    "                'SVM': {'C': np.logspace(-3, 3, 14),\n",
    "                        'gamma': np.logspace(-5, 0, 12)}\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['model', 'best_params',\n",
    "                           'train_accuracy', 'test_accuracy', 'train_recall',\n",
    "                           'test_recall', 'train_f1', 'test_f1', 'RR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in models.keys():\n",
    "    \n",
    "    print('\\nGrid search using {} model ...\\n'.format(model_name))\n",
    "    \n",
    "    params = params_model[model_name]\n",
    "    \n",
    "    model = models[model_name]\n",
    "    \n",
    "    grid = GridSearchCV(model, \n",
    "                        param_grid = params, \n",
    "                        cv = 5,\n",
    "                        scoring = 'accuracy',\n",
    "                        verbose = 1,\n",
    "                        n_jobs = -1,\n",
    "                        return_train_score = True)\n",
    "    \n",
    "    grid.fit(Z_train, y_train);\n",
    "    \n",
    "    df_test['pred'] = grid.predict(Z_test)\n",
    "    df_test['correct'] = df_test.apply(lambda x: 1 if x['Label'] == x['pred'] else 0, axis=1)\n",
    "    RR = df_test.groupby('Patient_Id')[['correct']].agg('mean').sum().values[0] / len(df_test.groupby('Patient_Id'))\n",
    "    \n",
    "    output = {}\n",
    "    output['model'] = model_name\n",
    "    output['best_params'] = grid.best_params_\n",
    "    output['train_accuracy'] = grid.best_score_\n",
    "    output['test_accuracy'] = grid.score(Z_test, y_test)\n",
    "    output['train_recall'] = recall_score(y_train, grid.predict(Z_train))\n",
    "    output['test_recall'] = recall_score(y_test, df_test['pred'])\n",
    "    output['train_f1'] = fbeta_score(y_train, grid.predict(Z_train), 1)\n",
    "    output['test_f1'] = fbeta_score(y_test, df_test['pred'], 1)\n",
    "    output['RR'] = RR\n",
    "    \n",
    "    df = df.append(output, ignore_index=True)\n",
    "    \n",
    "    df.to_csv('results_pca.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
